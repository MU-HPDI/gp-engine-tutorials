{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b5d3eac-6c77-4599-ab2b-2755f4707387",
   "metadata": {},
   "source": [
    "# Training SKLearn Models on Kubernetes\n",
    "\n",
    "This notebook will walk through using Kubernetes to train an SKLearn model in a Kubernetes Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb211dfb-5a2e-42b5-9fa0-0621086e6054",
   "metadata": {},
   "source": [
    "## Step 0: Prerequisites\n",
    "\n",
    "1. You must have an NRP account\n",
    "2. You must have been added to a Nautilus namespace\n",
    "3. You must have your NRP config in the `~/.kube` directory. There is a notebook to assist you [here](./NautilusConfigSetup.ipynb).\n",
    "4. You must have a PVC on the Nautilus cluster in your assigned namespace\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3b514e-74cc-4544-9ab7-3e20e6cd55ef",
   "metadata": {},
   "source": [
    "# Step 1: Building a Training Script \n",
    "\n",
    "The first step is to build a script to perform the training (and/or testing)\n",
    "\n",
    "Let's build this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77adbb23-8070-44a1-be5b-e1cd13f2060e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from skimage.feature import hog\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "NUM_TREES = int(os.environ.get(\"SK_NUM_TREES\", \"3\"))\n",
    "NUM_JOBS = int(os.environ.get(\"SK_NUM_JOBS\", \"1\"))\n",
    "\n",
    "print(f\"Running random forest with {NUM_TREES} trees and {NUM_JOBS} jobs\")\n",
    "\n",
    "######\n",
    "# Download MNIST\n",
    "######\n",
    "train_dataset = MNIST(download=True, root=\"~/data\", train=True)\n",
    "test_dataset = MNIST(download=True, root=\"~/data\", train=False)\n",
    "\n",
    "##### \n",
    "# Generate Train Features\n",
    "#####\n",
    "print(\"Generating Train Features\")\n",
    "train_features = np.empty((len(train_dataset), 108))\n",
    "train_labels = np.empty(len(train_dataset), np.int32)\n",
    "for i, (img, label) in tqdm(enumerate(train_dataset), ncols=80, total=len(train_dataset)):\n",
    "    train_features[i] = hog(np.asarray(img), orientations=12, cells_per_block=(3,3))\n",
    "    train_labels[i] = label\n",
    "\n",
    "#####\n",
    "# Generate Test Features\n",
    "#####\n",
    "print(\"Generating Test Features\")\n",
    "test_features = np.empty((len(test_dataset), 108))\n",
    "test_labels = np.empty(len(test_dataset), np.int32)\n",
    "for i, (img, label) in tqdm(enumerate(test_dataset), ncols=80, total=len(test_dataset)):\n",
    "    test_features[i] = hog(np.asarray(img), orientations=12, cells_per_block=(3,3))\n",
    "    test_labels[i] = label\n",
    "\n",
    "######\n",
    "# Train Model\n",
    "#######\n",
    "print(\"Training the model\")\n",
    "model = RandomForestClassifier(n_estimators=NUM_TREES, n_jobs=NUM_JOBS, verbose=1)\n",
    "model.fit(train_features, train_labels)\n",
    "\n",
    "####\n",
    "# Score Model\n",
    "#####\n",
    "print(\"Evaluating the model\")\n",
    "model_accuracy = model.score(test_features, test_labels)\n",
    "print(f\"Model Accuracy = {model_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a5534-fb97-4be1-87e1-8fa171968079",
   "metadata": {},
   "source": [
    "# Step 2: Copying Our Script to the Cluster\n",
    "\n",
    "### Step 2A: Copy Code to a File\n",
    "The code we have written above has been copied to a script in the scripts directory named [RandomForestMNIST.py](../scripts/RandomForestMNIST.py).\n",
    "\n",
    "### Step 2B: Spawn Pod with PVC\n",
    "You now need to spawn a pod on the cluster with your peristent volume attached\n",
    "\n",
    "For a refresher, [here is a sample YAML file](../yaml/pod_pvc.yml). Be sure to change the `name` of the pod and the `persistentVolume-name`\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: pod-name-sso\n",
    "spec:\n",
    "  containers:\n",
    "  - name: pod-name-sso\n",
    "    image: ubuntu:20.04\n",
    "    command: [\"sh\", \"-c\", \"echo 'Im a new pod' && sleep infinity\"]\n",
    "    resources:\n",
    "      limits:\n",
    "        memory: 12Gi\n",
    "        cpu: 2\n",
    "      requests:\n",
    "        memory: 10Gi\n",
    "        cpu: 2\n",
    "    volumeMounts:\n",
    "    - mountPath: /data\n",
    "      name: persistentVolume-name\n",
    "  volumes:\n",
    "    - name: persistentVolume-name\n",
    "      persistentVolumeClaim:\n",
    "        claimName: persistentVolume-name\n",
    "```\n",
    "\n",
    "Once you have updated those values, you can run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf4e7b-1094-48c6-9600-efc8eaed4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl create -f ../yaml/pod_pvc.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0405a3-3d72-46e4-9ca7-7dd3106fa8b9",
   "metadata": {},
   "source": [
    "### Step 2C: Copy the File to the PVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ffcb2d-9633-4a14-a163-4c5d226376ed",
   "metadata": {},
   "source": [
    "Run the following cell until your pod is `Running`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d5f0c2-2bee-411f-8f45-9f19dad63cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826cdd08-61e7-4914-bf97-4d0c2a6b3dea",
   "metadata": {},
   "source": [
    "Once your pod is running, we can copy our script to the PVC attached to the pod. Change `PODNAME` to your podname:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ceb097-70cf-4434-87ab-05845834e6a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! kubectl cp ../scripts/RandomForestMNIST.py PODNAME:/data/RandomForestMNIST.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c83703d-4bbe-40dc-a97b-4c7183fca575",
   "metadata": {},
   "source": [
    "We can check that our copy was successful with the `exec` subcommand in `kubectl`. Again, replace PODNAME with your pod's name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062606ff-a1d9-4e85-ac68-cb5a9711b290",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl exec PODNAME -- cat /data/RandomForestMNIST.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ae4f6-5ed5-4988-b154-25d270f8e70a",
   "metadata": {},
   "source": [
    "# Step 3: Building a Container Image\n",
    "\n",
    "The next step is to build and push a container to a container registry, but we can just use the same container image that is currently running this Jupyter instance, since it has all the dependencies we need:\n",
    "```\n",
    "gitlab-registry.nrp-nautilus.io/gp-engine/jupyter-stacks/bigdata-2023:latest\n",
    "```\n",
    "\n",
    "The `Dockerfile` for this image is in the docker directory of this repository [here](../docker/Dockerfile). However, in other contexts, you may need to write your own `Dockerfile` and build and push it yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c61a9-e38e-486b-8db7-e95a4cbdf578",
   "metadata": {},
   "source": [
    "# Step 4: Building the Job Specification YAML\n",
    "\n",
    "We now have everything we need to run our train and evaluation job. The final to-do item is to create a YAML Job Specification file. There is a template file for this in the repository [here](../yaml/sklearn_job_template.yml)\n",
    "\n",
    "```yaml\n",
    "apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: {{ job_name }}\n",
    "spec:\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: sklearn-train-container\n",
    "        image: gitlab-registry.nrp-nautilus.io/gp-engine/jupyter-stacks/bigdata-2023:latest\n",
    "        workingDir: /data\n",
    "        env:\n",
    "            - name: SK_NUM_TREES\n",
    "              value: \"{{ num_trees }}\"\n",
    "            - name: SK_NUM_JOBS\n",
    "              value: \"{{ num_jobs }}\"\n",
    "        command: [\"python3\", \"/data/RandomForestMNIST.py\"]\n",
    "        volumeMounts:\n",
    "            - name: {{ pvc_name }}\n",
    "              mountPath: /data\n",
    "        resources:\n",
    "            limits:\n",
    "              memory: 1Gi\n",
    "              cpu: \"{{ num_jobs }}\"\n",
    "            requests:\n",
    "              memory: 1Gi\n",
    "              cpu: \"{{ num_jobs }}\"    \n",
    "      volumes:\n",
    "      - name: {{ pvc_name }}\n",
    "        persistentVolumeClaim:\n",
    "            claimName: {{ pvc_name }}\n",
    "      restartPolicy: Never      \n",
    "  backoffLimit: 1\n",
    "```\n",
    "\n",
    "Let's use `jinja2` to fill in the missing values in our Template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4a318-9fcc-49ad-953d-2f0751f24b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "# read in the template\n",
    "with open('../yaml/sklearn_job_template.yml') as file_:\n",
    "    template = Template(file_.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da86bf-5a17-47bb-ad44-5f24cf740585",
   "metadata": {},
   "source": [
    "Replace the arguments to the `render` function with the appropriate values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a90a4-12a0-4ba9-8a49-2ce73ca48ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render the job spec\n",
    "job_spec = template.render(\n",
    "    job_name=\"JOBNAME\",\n",
    "    pvc_name=\"PVC NAME\",\n",
    "    num_trees=1,\n",
    "    num_jobs=1\n",
    ")\n",
    "\n",
    "# print the job spec\n",
    "print(job_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742f07d6-f176-46cc-b0ca-d376a60e7db3",
   "metadata": {},
   "source": [
    "Now, let's save it to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba13a65-082a-4ba2-ac59-415a740dadca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./sklearn_job.yml\", \"w\") as file:\n",
    "    file.write(job_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5583e883-071d-4082-9776-98960befa5ff",
   "metadata": {},
   "source": [
    "# Step 5: Start the Job\n",
    "\n",
    "Run the cell below to start the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b963bb-5e36-46c8-bee7-0e94079dda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl create -f ./sklearn_job.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132c3fa-0d5e-47a6-9605-8533fa3b6fe1",
   "metadata": {},
   "source": [
    "Run the cell below until your job moves to the `Complete` status. It will go through the stages of: `Pending`, `ContainerCreating`, and `Running`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d8fd6-5e26-4688-9a6c-81cd457cbb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a2a770-456d-4ae3-923f-e873f04c3ef5",
   "metadata": {},
   "source": [
    "# Step 6: Review the Output of the Job\n",
    "\n",
    "As you can see in the output from Step 5, your job created a pod with the name of `job-ABCDE`. Let's check the output of that pod to see our accuracy. Change `PODNAME` below to the correct pod name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be89dc-3e1e-4848-8cc8-38388437c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl logs --tail=1 PODNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e4cb6-a02a-4b83-b0e3-4869cdbbffe1",
   "metadata": {},
   "source": [
    "# Step 7: Delete the Job and the Pod\n",
    "\n",
    "The final step is to delete the job we ran the pod we spawned. Please change `JOBNAME` and `PODNAME` below to the appropriate name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183edc64-8802-4e81-b54e-dfe5cc1e90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl delete job JOBNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c6581-c076-477d-8e57-7421cb8c29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl delete pod PODNAME"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
