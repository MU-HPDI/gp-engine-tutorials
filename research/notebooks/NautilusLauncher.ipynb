{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181754b9-963b-4da7-a222-31e93cb5b3bf",
   "metadata": {},
   "source": [
    "# Automating and Scaling Deep Learning on Kubernetes using Nautilus Job Launcher\n",
    "\n",
    "This notebook will walk through using the [Nautilus Job Launcher](https://github.com/MU-HPDI/Nautilus-Job-Launcher) library to launch multiple jobs from a file config and dictionary config, as well as how to integrate the library into your own Python scripts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de7890-0ba3-4cca-a5d4-7b9dc7b0372a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Nautilus Job Launcher Configuration\n",
    "\n",
    "Each job passed to the Nautilus Job Launcher must be configured via a set of key/value pairs, via either YAML or Dictionary as we'll see in the sections below.\n",
    "\n",
    "### Required Keys\n",
    "\n",
    "| Key        | Description             |       Type        |\n",
    "| :--------- | :---------------------- | :---------------: |\n",
    "| `job_name` | Name of the job         |       `str`       |\n",
    "| `image`    | Container image URI     |       `str`       |\n",
    "| `command`  | Command to run on start | `str`/`List[str]` |\n",
    "\n",
    "### Optional Keys\n",
    "\n",
    "| Key          | Description                             |          Type          | Default Value |\n",
    "| :----------- | :-------------------------------------- | :--------------------: | :-----------: |\n",
    "| `workingDir` | Working directory when container starts |         `str`          |     None      |\n",
    "| `env`        | Environment variables                   | `Dict`: `str` -> `str` |     None      |\n",
    "| `volumes`    | PVC and SHM volumes                     | `Dict`: `str` -> `str` |     None      |\n",
    "| `ports`      | Container ports to expose               |      `List[int]`       |     None      |\n",
    "| `min_cpu`    | Min number of CPUs                      |         `int`          |       2       |\n",
    "| `max_cpu`    | Max number of CPUs                      |         `int`          |       4       |\n",
    "| `min_ram`    | Min GB of RAM                           |         `int`          |       4       |\n",
    "| `max_ram`    | Max GB of RAM                           |         `int`          |       8       |\n",
    "| `gpu`        | Number of GPUs                          |         `int`          |       0       |\n",
    "| `gpu_types`  | Types of GPUs for Job                   |      `List[str]`       |     None      |\n",
    "| `shm`        | When true, add shared memory            |         `bool`         |     False     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5a7d8-6fb5-4525-bee3-c70f778dabc2",
   "metadata": {},
   "source": [
    "## Part 1: Using a Dictionary\n",
    "\n",
    "You can use a Python `dict` object to configure a set of jobs that will all be run.\n",
    "\n",
    "Be sure to update the `namespace` and `job_prefix` variables below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3024bc85-31fa-4c29-89af-a626204ac40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nautiluslauncher import NautilusJobLauncher\n",
    "\n",
    "namespace = None\n",
    "job_prefix = \"myname-\"\n",
    "command = [\"python\", \"-c\", \"print('hello world')\"]\n",
    "\n",
    "jobs = {\n",
    "    \"namespace\": namespace,\n",
    "    \"jobs\": [\n",
    "        {\"image\": \"python:3.6\", \"command\": command, \"job_name\": job_prefix + \"1\"},\n",
    "        {\"image\": \"python:3.7\", \"command\": command, \"job_name\": job_prefix + \"2\"},\n",
    "        {\"image\": \"python:3.8\", \"command\": command, \"job_name\": job_prefix + \"3\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64edb90a-3406-4a87-a361-aa3db4adedf6",
   "metadata": {},
   "source": [
    "Once we've build our dictionary, we can pass it to the constructor of the job launcher:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fe850-5796-44b8-9b37-b1dfd18a6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "launcher = NautilusJobLauncher(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57110d20-5560-432c-9f47-203300d1da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "launcher.jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eaa8ac-2d97-4d4a-b866-d3755446ac0e",
   "metadata": {},
   "source": [
    "To launch the jobs, we can call the `run` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158fb679-0616-4dfc-836e-608a8238d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "launcher.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ff632-5f02-4041-bdb5-7f401deae067",
   "metadata": {},
   "source": [
    "We can now see all the jobs have been created:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe351ac2-8d5d-47cf-a9ee-48705032808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5cd81-7ccb-4088-a862-a29af1dde786",
   "metadata": {},
   "source": [
    "## Part 2: Templating Jobs with Dictionaries and YAML Files\n",
    "\n",
    "As we've seen in the SKLearn and ViT exercises, we often want to start with a template of a job, be that a CPU ML task or GPU ML task, and simply update the values. The Nautilus Job Launcher library allows us to do that with a YAML file.\n",
    "\n",
    "This is done using a `defaults` key and then a set of jobs. Every job will inherit the values in `defaults` and then optionally override them.\n",
    "\n",
    "Here's an example YAML file to do this:\n",
    "\n",
    "```yaml\n",
    "defaults:\n",
    "  command: [\"python\", \"-c\", \"print('hello world')\"]\n",
    "\n",
    "jobs:\n",
    "  - job_name: myjob-1\n",
    "    container: python:3.7\n",
    "  - job_name: myjob-2\n",
    "    container: python:3.8\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263fbba-50c0-4970-8f73-319f671b68e3",
   "metadata": {},
   "source": [
    "### Part 2A: Build Updated Script\n",
    "\n",
    "To show the capabilities of this automation client in Python, let's update our script from the [ViT Exercise](./VisionTransformerCifar10.ipynb) to be able to dynamically select a model from an environment variable. First, we'll need a function that can take in the name of a model and return the fully configured PyTorch object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ffd48-80a0-4b9f-badc-a0710f1e8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import (\n",
    "    vit_b_16,\n",
    "    ViT_B_16_Weights,\n",
    "    resnet18,\n",
    "    ResNet18_Weights,\n",
    "    mobilenet_v2,\n",
    "    MobileNet_V2_Weights,\n",
    ")\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def build_model(model_name):\n",
    "    if model_name == \"ViT\":\n",
    "        model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "        model.heads[0] = nn.Linear(768, 10)\n",
    "        model.encoder.requires_grad_(False)\n",
    "    elif model_name == \"ResNet\":\n",
    "        model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.fc.requires_grad_(True)\n",
    "    elif model_name == \"MobileNet\":\n",
    "        model = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V2)\n",
    "        model.classifier = nn.Linear(model.classifier[1].in_features, 10)\n",
    "        model.features.requires_grad_(False)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid Model: {model_name}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a138c5da-c545-463b-9434-98276f01b352",
   "metadata": {},
   "source": [
    "Now we can update the model section of the script to:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d187257-3dd3-477f-9a8d-0b8e0b414450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TORCH_MODEL_NAME = os.environ.get(\"TORCH_MODEL_NAME\", \"ViT\")\n",
    "\n",
    "model = build_model(TORCH_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d0b1a-57fa-4cb8-a9bd-03d346eaf83a",
   "metadata": {},
   "source": [
    "### Part 2B: Upload the Updated Script\n",
    "\n",
    "We've placed the updated version of the script to the scripts directory, and named it [MultiModelCifar10.ipynb](../scripts/MultiModelCifar10.ipynb). Let's copy this script to our PVC using a pod on the cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf4900-8957-449a-a5b1-0a80be39df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl create -f ../yaml/pod_pvc.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434fe085-8ee5-4101-8216-63c592de5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl cp ../scripts/MultiModelCifar10.py PODNAME:/data/MultiModelCifar10.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b91916-7a33-4a09-83b6-e3702cff71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl exec PODNAME -- cat /data/MultiModelCifar10.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4996761-be4e-465d-b5b6-9b1ae1878540",
   "metadata": {},
   "source": [
    "### Part 2C: Building the Configuration Dictionary\n",
    "\n",
    "In previous exercises, we needed to build the Kubernetes YAML Spec by hand. In this exercise, we are instead going to build a configuration dictionary.\n",
    "\n",
    "First, we define the defaults, i.e., what each job will start with. We can override these values for individual jobs as necessary. Be sure to set the `pvc_name` to your PVC name:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a029a14-542d-4b87-aa1a-2a0da763cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvc_name = None\n",
    "\n",
    "\n",
    "defaults = dict(\n",
    "    image=\"gitlab-registry.nrp-nautilus.io/gp-engine/jupyter-stacks/bigdata-2023:latest\",\n",
    "    command=[\"python3\", \"/data/MultiModelCifar10.py\"],\n",
    "    workingDir=\"/data\",\n",
    "    volumes={pvc_name: \"/data\"},\n",
    "    shm=True,\n",
    "    min_cpu=8,\n",
    "    max_cpu=8,\n",
    "    min_ram=8,\n",
    "    max_ram=8,\n",
    "    gpu=1,\n",
    "    env=dict(TORCH_NUM_JOBS=8, TORCH_NUM_EPOCHS=1),\n",
    ")\n",
    "\n",
    "defaults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f161ac15-a478-410d-8f49-08728608f527",
   "metadata": {},
   "source": [
    "Now we can define the jobs with what needs to be unqiue to each job. In this case, just the name and the model name. Ensure you update the job names to be unique in the namespace:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea97281-01ef-45cc-aa82-f0ad63207717",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [\n",
    "    dict(job_name=f\"jobname-{i+1}\", env=dict(TORCH_MODEL_NAME=m))\n",
    "    for i, m in enumerate([\"ViT\", \"ResNet\", \"MobileNet\"])\n",
    "]\n",
    "\n",
    "jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a347a29-fdd1-4b05-994e-81016e48010e",
   "metadata": {},
   "source": [
    "### Part 2C: Create Job Launcher Object\n",
    "\n",
    "Be sure to update the `NAMESPACE` variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc2d747-f698-4f82-854f-a5ba796ec61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMESPACE = None\n",
    "\n",
    "launcher = NautilusJobLauncher(\n",
    "    cfg=dict(namespace=NAMESPACE, defaults=defaults, jobs=jobs)\n",
    ")\n",
    "\n",
    "launcher.jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4232093-c160-4b74-8b2f-5785db918f0d",
   "metadata": {},
   "source": [
    "We can now check the full configuration of the jobs (with defaults intertwined) using the `dryrun` flag:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d29ac58-60ba-4c63-a01f-793a238407f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "launcher.run(dryrun=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d19dafc-1870-40a6-a566-e26bc8df8720",
   "metadata": {},
   "source": [
    "And finally, we can kick off the jobs, by removing the `dryrun` flag:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fbab90-deed-4af0-942f-8d5c37ed5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "launcher.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c53df-3ea1-4f3d-b4b9-4bd30b072841",
   "metadata": {},
   "source": [
    "And now we can watch the jobs run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaee0f0-1638-4736-b758-2760ea71dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c763d-5a7d-4de7-a897-664c4e6144bc",
   "metadata": {},
   "source": [
    "### Part 2D: Comapring Results\n",
    "\n",
    "By configuring our dictionary correctly and using templating, we have easily trained and tested 3 separate models on CIFAR-10. We can now check the outputs to compare the performance of the models.\n",
    "\n",
    "Be sure to update the pod names in the cells below to match your pod names. (1) is ViT, (2) is ResNet, and (3) is MobileNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0690fd32-4baa-4ba7-af05-9aa8d8a59950",
   "metadata": {},
   "source": [
    "##### ViT Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bbe140-9abc-4090-8e4b-9f50c24da7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl logs --tail=5 jobname-1-REPLACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696a216-acb8-434d-868c-ad227062b193",
   "metadata": {},
   "source": [
    "##### ResNet18 Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5cc26-1d68-4763-bb8d-8d0cee6de8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl logs --tail=5 jobname-2-REPLACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8978d300-076b-46d9-8b97-cae026b44f83",
   "metadata": {},
   "source": [
    "##### MobileNetV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ac495-9cc4-42e1-9e71-3bcfd3315b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl logs --tail=5 jobname-3-REPLACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677a3f1-9408-4379-bc2f-8cbbe67145f7",
   "metadata": {},
   "source": [
    "## Part 3: Integration with Python\n",
    "\n",
    "Thus far, we have used the Nautilus Job Launcher as a pure runner, where we hand it a Python dictionary (or YAML file), and have it launch the jobs. Here, we will look at an object oriented approach to job creation.\n",
    "\n",
    "We will use a different class, the `NautilusAutomationClient`, which accepts `Job` objects that we can create on the fly.\n",
    "\n",
    "Let's start by creating our client:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dead5e-01fb-4e76-ad8e-cac1a4723d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nautiluslauncher import Job, NautilusAutomationClient\n",
    "\n",
    "NAMESPACE = None\n",
    "\n",
    "client = NautilusAutomationClient(NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b16c172-a98b-4847-9bba-498e89fd6837",
   "metadata": {},
   "source": [
    "We can now create job objects, where the key/values from our dictionary become parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce6003-e1cf-40a1-a1f7-84cb98b33479",
   "metadata": {},
   "outputs": [],
   "source": [
    "job1 = Job(\n",
    "    image=\"ubuntu:20.04\", command=[\"echo\", \"'Hello World'\"], job_name=\"my-ubuntu-job\"\n",
    ")\n",
    "job2 = Job(image=\"python:3.8\", command=[\"ls\", \"/etc\"], job_name=\"my-python-job\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f015af3b-e610-4abd-a564-fa520cb5fb7c",
   "metadata": {},
   "source": [
    "And our client can create jobs as well:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da536a3c-f159-434f-a56c-61ab52f3e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_job(job1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93563271-a244-4b3f-ab40-87663d732330",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_job(job2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ff4ab1-b863-49d0-9e9c-5202c23b98e1",
   "metadata": {},
   "source": [
    "We can also get the details of all the jobs in our namespace using the `list_pods` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494d54b-ca55-4734-8478-5cc0806bb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_pods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22700c4c",
   "metadata": {},
   "source": [
    "## Part 4: Removing Resources\n",
    "\n",
    "Please be sure to remove your completed jobs and running pods!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
